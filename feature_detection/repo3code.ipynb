{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "# find repo root -> feature_detection\n",
    "p = Path.cwd()\n",
    "while p != p.parent and not (p / \"feature_detection\").exists():\n",
    "    p = p.parent\n",
    "fd = p / \"feature_detection\"\n",
    "\n",
    "# paths\n",
    "img_path = fd / \"images\" / \"example-image.jpg\"\n",
    "out_path = fd / \"images\" / \"example-image_sift_keypoints.png\"\n",
    "\n",
    "# load gray\n",
    "gray = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# SIFT detect (defaults) and draw rich keypoints\n",
    "sift = cv2.SIFT_create()\n",
    "kps = sift.detect(gray, None)\n",
    "out = cv2.drawKeypoints(gray, kps, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# save viz\n",
    "cv2.imwrite(str(out_path), out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Find feature_detection/ directory regardless of working directory\n",
    "p = Path.cwd()\n",
    "while p != p.parent and not (p / \"feature_detection\").exists():\n",
    "    p = p.parent\n",
    "fd = p / \"feature_detection\"\n",
    "\n",
    "gray = cv2.imread(str(fd / \"images\" / \"example-image.jpg\"), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Compare a few tuned SIFT variants\n",
    "variants = {\n",
    "    \"Default\": cv2.SIFT_create(),\n",
    "    \"Higher contrastThreshold (0.1)\": cv2.SIFT_create(contrastThreshold=0.1),\n",
    "    \"Lower edgeThreshold (5)\": cv2.SIFT_create(edgeThreshold=5)\n",
    "}\n",
    "\n",
    "# Save the best (Default in this example) to images folder\n",
    "best_sift = cv2.SIFT_create(edgeThreshold=5)\n",
    "kps = best_sift.detect(gray, None)\n",
    "out = cv2.drawKeypoints(gray, kps, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite(str(fd / \"images\" / \"example-image_sift_tuned.png\"), out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Locate repo dir + load grayscale\n",
    "p = Path.cwd()\n",
    "while p != p.parent and not (p / \"feature_detection\").exists():\n",
    "    p = p.parent\n",
    "fd = p / \"feature_detection\"\n",
    "img_path = fd / \"images\" / \"example-image.jpg\"\n",
    "\n",
    "gray = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Detect keypoints (tuned like Part 2) and compute descriptors\n",
    "sift = cv2.SIFT_create(edgeThreshold=5)\n",
    "kps = sift.detect(gray, None)\n",
    "kps, desc = sift.compute(gray, kps)  \n",
    "\n",
    "# Pick one keypoint (strongest response)\n",
    "idx = int(np.argmax([kp.response for kp in kps]))\n",
    "kp = kps[idx]\n",
    "d = desc[idx]               # (128,)\n",
    "\n",
    "rgb = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n",
    "x, y = kp.pt\n",
    "s = kp.size                 # diameter of the region\n",
    "half = int(round(s/2))\n",
    "x1, y1 = int(x - half), int(y - half)\n",
    "x2, y2 = int(x + half), int(y + half)\n",
    "cv2.circle(rgb, (int(x), int(y)), 3, (255, 0, 0), -1)\n",
    "cv2.rectangle(rgb, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "# Reshape 128-D descriptor to 4x4 cells × 8 bins\n",
    "grid = d.reshape(4, 4, 8)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.imshow(rgb)\n",
    "ax1.set_title(\"Keypoint & patch (scale from size)\")\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "# Build a small matrix summarizing the dominant bin per cell to keep it minimal\n",
    "dom = np.argmax(grid, axis=2)   # 4x4 of [0..7]\n",
    "im = ax2.imshow(dom, vmin=0, vmax=7)\n",
    "ax2.set_title(\"Descriptor (4×4 cells, value = dominant orientation bin)\")\n",
    "ax2.set_xticks(range(4)); ax2.set_yticks(range(4))\n",
    "plt.colorbar(im, ax=ax2, fraction=0.046, pad=0.04, ticks=range(8))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save final composite output\n",
    "out_path = fd / \"images\" / \"example-image_sift_descriptor.png\"\n",
    "fig.savefig(str(out_path), dpi=200, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "p = Path.cwd()\n",
    "while p != p.parent and not (p / \"feature_detection\").exists():\n",
    "    p = p.parent\n",
    "fd = p / \"feature_detection\"\n",
    "\n",
    "# paths\n",
    "img1_path = fd / \"images\" / \"example-image.jpg\"\n",
    "img2_path = fd / \"images\" / \"example-image-transformed.jpg\"\n",
    "matches_path = fd / \"images\" / \"example-image_matches_top50.png\"\n",
    "\n",
    "# load original (gray for SIFT, color only for drawing later)\n",
    "img1_gray = cv2.imread(str(img1_path), cv2.IMREAD_GRAYSCALE)\n",
    "img1_bgr  = cv2.cvtColor(img1_gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# make a simple transformed copy of image1 (rotation + slight scale)\n",
    "h, w = img1_gray.shape\n",
    "M = cv2.getRotationMatrix2D((w//2, h//2), 20, 0.9)  # 20° rotate, 0.9 scale\n",
    "img2_gray = cv2.warpAffine(img1_gray, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "img2_bgr  = cv2.cvtColor(img2_gray, cv2.COLOR_GRAY2BGR)\n",
    "cv2.imwrite(str(img2_path), img2_gray)  # save the transformed image\n",
    "\n",
    "sift = cv2.SIFT_create(edgeThreshold=5)\n",
    "kp1, des1 = sift.detectAndCompute(img1_gray, None)\n",
    "kp2, des2 = sift.detectAndCompute(img2_gray, None)\n",
    "\n",
    "# brute-force match with L2, enforce 1-1 matches\n",
    "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "matches = bf.match(des1, des2)\n",
    "matches = sorted(matches, key=lambda m: m.distance)[:50]  # top 50 for clarity\n",
    "\n",
    "# draw and save the match viz\n",
    "matched = cv2.drawMatches(\n",
    "    img1_bgr, kp1,\n",
    "    img2_bgr, kp2,\n",
    "    matches, None,\n",
    "    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    ")\n",
    "cv2.imwrite(str(matches_path), matched)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
